{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Write Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam\n",
    "import csv\n",
    "import os \n",
    "from typing import NamedTuple\n",
    "from apache_beam.io.gcp.bigquery import WriteToBigQuery\n",
    "from google.cloud import bigquery\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Create a Pipeline Object with Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_options = PipelineOptions(\n",
    "    runner='DirectRunner',\n",
    "    project='andrii-edu-bigquery',\n",
    "    temp_location='gs://airbnb-educative-source-data/tmp/',\n",
    "    staging_location='gs://airbnb-educative-source-data/staging',\n",
    "    job_name='etl-pipeline',\n",
    "    machine_type='e2-standard-2',\n",
    "    flags=[],\n",
    "    num_workers=1,\n",
    "    max_num_workers=1,\n",
    "    region='us-central1',\n",
    "    save_main_session=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypipeline = beam.Pipeline(options=pipeline_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Read Data from GCS Bucket in the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/usercode/etl-pipeline-key.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_bucket = 'airbnb-educative-source-data'\n",
    "csv_file_path = 'airbnb_data.csv'\n",
    "gcs_path = f'gs://{gcs_bucket}/{csv_file_path}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": "\n        if (typeof window.interactive_beam_jquery == 'undefined') {\n          var jqueryScript = document.createElement('script');\n          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n          jqueryScript.type = 'text/javascript';\n          jqueryScript.onload = function() {\n            var datatableScript = document.createElement('script');\n            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n            datatableScript.type = 'text/javascript';\n            datatableScript.onload = function() {\n              window.interactive_beam_jquery = jQuery.noConflict(true);\n              window.interactive_beam_jquery(document).ready(function($){\n                \n              });\n            }\n            document.head.appendChild(datatableScript);\n          };\n          document.head.appendChild(jqueryScript);\n        } else {\n          window.interactive_beam_jquery(document).ready(function($){\n            \n          });\n        }"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_data = (\n",
    "    mypipeline\n",
    "    | 'Read CSV' >> beam.io.ReadFromText(gcs_path, skip_header_lines=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: Parse the Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirbnbData(NamedTuple):\n",
    "    id: str\n",
    "    name: str\n",
    "    host_id: str\n",
    "    host_name: str\n",
    "    neighbourhood_group: str\n",
    "    neighbourhood: str\n",
    "    latitude: str\n",
    "    longitude: str\n",
    "    room_type: str\n",
    "    price: str\n",
    "    minimum_nights: str\n",
    "    number_of_reviews: str\n",
    "    last_review: str\n",
    "    reviews_per_month: str\n",
    "    calculated_host_listings_count: str\n",
    "    availability_365: str\n",
    "    number_of_reviews_ltm: str\n",
    "    license: str\n",
    "    price_type: str = ''\n",
    "    neighborhood_avg_price: float = 0\n",
    "    price_usd: float = 0\n",
    "    lr_year: str = ''\n",
    "    lr_month: str = ''\n",
    "    lr_day: str = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = (\n",
    "    csv_data\n",
    "    | 'Parse CSV' >> beam.Map(lambda row: AirbnbData(*next(csv.reader([row]))))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9: Define Data Validation Functions in the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = (\n",
    "    parsed_data\n",
    "    | 'Filter positive prices' >> beam.Filter(lambda row: int(row.price) >= 0)\n",
    "    | 'Filter abnormal coordinates' >> beam.Filter(\n",
    "        lambda row: (\n",
    "            -90.0 <= float(row.latitude) <= 90.0 and\n",
    "            -180.0 <= float(row.longitude) <= 180.0\n",
    "        )\n",
    "    )\n",
    "    | 'Filter non-null host IDs' >> beam.Filter(lambda row: row.host_id.strip() != '')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 10: Define Data Cleaning Functions in the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_data = (\n",
    "    filtered_data\n",
    "    | 'Remove duplicates' >> beam.Distinct()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_char_replaced = (\n",
    "    deduplicated_data\n",
    "    | 'Replace comma' >> beam.Map(lambda row: row._replace(**{'name': row.name.replace(',', '_')}))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_values(row):\n",
    "    return row._replace(\n",
    "        neighbourhood='not available' if row.neighbourhood in ('', None) else row.neighbourhood,\n",
    "        availability_365='0' if row.availability_365 in ('', None) else row.availability_365,\n",
    "        reviews_per_month='0' if row.reviews_per_month in ('', None) else row.reviews_per_month,\n",
    "        number_of_reviews_ltm='0' if row.number_of_reviews_ltm in ('', None) else row.number_of_reviews_ltm\n",
    "    )\n",
    "\n",
    "class ImputeValues(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        return [impute_values(element)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = (\n",
    "    special_char_replaced\n",
    "    | 'Impute values' >> beam.ParDo(ImputeValues())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 11: Define Data Enrichment Functions in the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_data = (\n",
    "    cleaned_data\n",
    "    | 'Classify PriceType' >> beam.Map(\n",
    "        lambda row: row._replace(price_type='economic' if int(row.price) < 50 else ('midrange' if 50 <= int(row.price) < 150 else 'luxury'))\n",
    "    )\n",
    "    | 'Convert to USD' >> beam.Map(\n",
    "        lambda row: row._replace(price_usd=float(row.price) * 0.66 )\n",
    "    )\n",
    "    | 'Extract date components' >> beam.Map(\n",
    "        lambda row: row._replace(\n",
    "            lr_year='',\n",
    "            lr_month='',\n",
    "            lr_day=''\n",
    "        ) if row.last_review in ('', None) else row._replace(\n",
    "            lr_year=int(datetime.strptime(row.last_review, '%Y-%m-%d').year),\n",
    "            lr_month=int(datetime.strptime(row.last_review, '%Y-%m-%d').month),\n",
    "            lr_day=int(datetime.strptime(row.last_review, '%Y-%m-%d').day)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 12: Perform Aggregation Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_price_per_neighborhood = (\n",
    "    enriched_data\n",
    "    | 'KeyBy Neighborhood' >> beam.Map(lambda row: (row.neighbourhood, float(row.price)))\n",
    "    | 'GroupBy Neighborhood' >> beam.GroupByKey()\n",
    "    | 'Compute avg price' >> beam.Map(lambda kv: (kv[0], sum(kv[1]) / len(kv[1])))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_data_with_avg_price = (\n",
    "    enriched_data\n",
    "    | 'Add NeighborhoodAvgPrice' >> beam.Map(\n",
    "        lambda row, avg_price_dict: row._replace(\n",
    "            neighborhood_avg_price=round(avg_price_dict.get(row.neighbourhood, 0), 2)\n",
    "        ),\n",
    "        avg_price_dict=beam.pvalue.AsDict(avg_price_per_neighborhood)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 13: Create BigQuery Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"andrii-edu-bigquery.airbnb_ds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = bigquery.Dataset(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.location = \"US\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = client.create_dataset(dataset, exists_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 14: Upload Final Data to BigQuery Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_table_spec = 'andrii-edu-bigquery:airbnb_ds.airbnb_tb'\n",
    "gcs_temp_location = 'gs://airbnb-educative-source-data/bigquery_temp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apache_beam.io.gcp.bigquery.WriteResult at 0x73521a630df0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(enriched_data_with_avg_price\n",
    "    | 'Convert to Dict' >> beam.Map(lambda row: row._asdict())\n",
    "    | 'Write to BigQuery' >> WriteToBigQuery(\n",
    "        output_table_spec,\n",
    "        schema='SCHEMA_AUTODETECT',\n",
    "        create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "        write_disposition=beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
    "        custom_gcs_temp_location=gcs_temp_location)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 15: Execute the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class '__main__.AirbnbData'>' in '[10]: Remove duplicates/Group/GroupByKey'. \n",
      "WARNING:apache_beam.coders.coder_impl:Using fallback deterministic coder for type '<class '__main__.AirbnbData'>' in '[10]: Remove duplicates/Group/GroupByKey'. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DONE'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = mypipeline.run()\n",
    "result.wait_until_finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "state = result.state\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 16: Create Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_id = \"andrii-edu-bigquery.airbnb_ds.airbnb_analysis_vw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ref = bigquery.Table(view_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_ref.view_query = \"\"\"\n",
    "SELECT\n",
    "  neighbourhood,\n",
    "  price_type,\n",
    "  ROUND(AVG(price), 2) AS avg_price,\n",
    "  ROUND(MIN(price), 2) AS min_price,\n",
    "  ROUND(MAX(price), 2) AS max_price,\n",
    "  MIN(neighborhood_avg_price) AS min_neighbourhood_avg_price,\n",
    "  MAX(neighborhood_avg_price) AS max_neighbourhood_avg_price\n",
    "FROM airbnb_ds.airbnb_tb\n",
    "GROUP BY neighbourhood, price_type \n",
    "ORDER BY neighbourhood, price_type;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = client.create_table(view_ref , exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 17: Validate the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mBQ CLI will soon require all users to log in using `gcloud auth login`. `bq\n",
      "init` will no longer handle authentication after January 1, 2024.\u001b[0m\n",
      "\n",
      "Welcome to BigQuery! This script will walk you through the \n",
      "process of initializing your .bigqueryrc configuration file.\n",
      "\n",
      "First, we need to set up your credentials if they do not \n",
      "already exist.\n",
      "\n",
      "Setting project_id andrii-edu-bigquery as the default.\n",
      "\n",
      "BigQuery configuration complete! Type \"bq\" to get started.\n",
      "\n",
      "+-------+\r\n",
      "|  f0_  |\r\n",
      "+-------+\r\n",
      "| 23171 |\r\n",
      "+-------+\r\n"
     ]
    }
   ],
   "source": [
    "!bq query --use_legacy_sql=false \"SELECT count(*) FROM airbnb_ds.airbnb_tb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-----------+-----------+-----------+-----------------------------+-----------------------------+\n",
      "| neighbourhood | price_type | avg_price | min_price | max_price | min_neighbourhood_avg_price | max_neighbourhood_avg_price |\n",
      "+---------------+------------+-----------+-----------+-----------+-----------------------------+-----------------------------+\n",
      "| Banyule       | economic   |     39.06 |      15.0 |      49.0 |                      158.01 |                      158.01 |\n",
      "| Banyule       | luxury     |     270.9 |     150.0 |    1200.0 |                      158.01 |                      158.01 |\n",
      "| Banyule       | midrange   |     95.36 |      50.0 |     149.0 |                      158.01 |                      158.01 |\n",
      "| Bayside       | economic   |     34.33 |      25.0 |      40.0 |                      380.25 |                      380.25 |\n",
      "| Bayside       | luxury     |    515.66 |     150.0 |   11429.0 |                      380.25 |                      380.25 |\n",
      "| Bayside       | midrange   |    101.06 |      50.0 |     149.0 |                      380.25 |                      380.25 |\n",
      "| Boroondara    | economic   |     36.98 |      13.0 |      49.0 |                      383.81 |                      383.81 |\n",
      "| Boroondara    | luxury     |    719.09 |     150.0 |  104983.0 |                      383.81 |                      383.81 |\n",
      "| Boroondara    | midrange   |     93.79 |      50.0 |     149.0 |                      383.81 |                      383.81 |\n",
      "| Brimbank      | economic   |     39.38 |      25.0 |      49.0 |                       122.6 |                       122.6 |\n",
      "+---------------+------------+-----------+-----------+-----------+-----------------------------+-----------------------------+\n"
     ]
    }
   ],
   "source": [
    "!bq query --use_legacy_sql=false \"SELECT * FROM airbnb_ds.airbnb_analysis_vw LIMIT 10\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 20: Validating the Pipeline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
